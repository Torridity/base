Architecture Overview
---------------------
In the following chapters basic components and concepts of the architecture of KIT Data Manager are described briefly. Basically, the presented components are responsible for 
abstracting from underlaying infrastructure and for providing a common service layer for integrating community-specific respository solutions.

[[FigureArchitecture]]
.Basic architecture of KIT Data Manager.
image::Architecture.png[Modules]

The <<FigureArchitecture,figure above>> shows a quite general view on the differnt layers and services provided by KIT Data Manager. The following table gives a short impression 
about the resposibilities of each service and in which chapter(s) the services are explained in detail.

[cols="m,n,o", options="header"]
|============================================================================================================================
|Service|Covered in chapter...|Short Description
|Data Sharing|<<ChapterAuthorization,Authorization>>|Authorizing access to data and functionality based on users, groups and roles.
|Metadata Management|<<ChapterMetadataManagement,Metadata Management>>|Managing and accessing different kinds of metadata.
|Search|<<ChapterMetadataManagement,Metadata Management>>,<<ChapterDataOrganization,Data Organization>>|Search for metadata.
|Staging|<<ChapterStaging,Staging>>, <<ChapterDataOrganization,Data Organization>>|Accessing and managing (file-based) data.
|Data Processing|Not available, yet.|Processing of data stored in a KIT Data Manager repository.
|Lifecycle Management|Not available, yet.|Services for managing a data lifecycle.
|Policy Enforcement|Not available, yet.|Services for enforcing policies on data.
|============================================================================================================================

Before we start describing each single component we like to go shortly into the main idea behind KIT Data Manager: to provide
a generic architecture for building up repository systems for arbitrary scientific communities. To be able to cope with the tasks of a repository system (e.g. content preservation,
bit preservation, curation...) there is the need to think in structured, `Digital Object`-based rather than in unstructured, File-based dimensions. Of course, in many cases there 
are files managed by KIT Data Manager on the lowest layer (see <<ChapterDataOrganization,Data Organization>>) but they are only one possible representation of the content of a Digital Object. 
The Digital Object and everything related to it is described by a huge amount of metadata in order to enable software systems to interpret Digital Objects, their content and their 
provenience. However, while reading the following chapters bear always in mind that everything in KIT Data Manager is related to structured data entities called
Digital Objects consisting of metadata and data.

[[ChapterAuthorization]]
Authorization
~~~~~~~~~~~~~

One of the core components which concerns almost every part of KIT Data Manager is the Authorization. It is based on users, groups and an effective role and determines if the 
access to a secured resource (e.g. Digital Objects) or operation (e.g. adding users) is granted or not. Authorization decisions in KIT Data Manager are always based on a 
specific context the user is currently working in. This context consists of:

UserId::
   An internal user identifier. This identifier is unique for each user and is assigned during registration, e.g. via a Community-specific Web frontend. 
   For real world applications, the user identifier should be obtained from another, central source like an LDAP database in order 
   to provide a common source of authentification for data and metadata access.
GroupId::
   An internal group id. This idenfier is unique for each user group of a KIT Data Manager instance. Available groups can be managed by higher level services. 
   By default, there is only one group with the id `USERS` which contains all registered users.

The final part needed for authorization decisions is the `Role`. A role forms, together with UserId and GroupId, the `AuthorizationContext` that is used to access 
resources or functionalities. Currently, there are the following roles available:

[cols="m,n", options="header"]
|============================================================================================================================
|Role|Description
|NO_ACCESS|An AuthorizationContext with this role has no access to any operation or resource.
|MEMBERSHIP_REQUESTED|This is an intermediate role used in special cases. 
 Users with this role have requested the membership for e.g. a group but are not activated, yet.
|GUEST|Using an AuthorizationContext with the role `GUEST` grants read access to public accessible resources. 
 Modifications of resources are not allowed.
|MEMBER|An AuthorizationContext with this role can be used to read and modify resources. This role should be used in most of all cases.
|MANAGER|An AuthorizationContext with the role `MANAGER` can be used for operations that require special access to resources and 
functionalities on a group level, e.g. assign new memberships to a group or deleting resources owned by a specific group.
|ADMINISTRATOR|The role `ADMINISTRATOR` is used for operations that require special access on a global level. Typically, the 
administrator role should be used sparingly and only for a small amount of administrator users.
|============================================================================================================================

Out of these roles, each user has a maximum role `MAX_ROLE` which is defined globally and cannot be bypassed.

[NOTE]
The MAX_ROLE defines the highest role a user may possess. This role might be further restricted on group- or resource-level, so that a maximum role of MANAGER may result in a 
group role MEMBER. On the other hand it is not possible to gain a higher role than MAX_ROLE, which means, if the maximum role of a user is set to NO_ACCESS, the user is not 
allowed to do anything and won't be able to gain more permissions on group- or resource-level. 

To determine the actual role within a specific context, a user has a group-specific role and the MAX_ROLE. The effective role is the group role unless MAX_ROLE is smaller. 
In this case MAX_ROLE is the effective role.

Additionally, there can be resource-specific roles issued separately. By default, each resource with restricted access can be accessed by all members of the creator's group 
with the role MANAGER (read and modify). For sharing purposes it is also possible to issue additional permissions for another groups (called `ResourceReferences`) 
or to single users (called `Grants`). This allows a user who is no member of the creator's group to access a single resource with a specific role.

Apart from access to resources also access to operations can be restricted. For basic services and components of KIT Data Manager the restriction for operations is 
roughly oriented on the role definition presented above. This means, that the role GUEST is needed to perform read operations, MEMBER is needed for basic write operations
and the MANAGER role entitles the user to remove data (to a very limited extent).

[[ChapterMetadataManagement]]
Metadata Management 
~~~~~~~~~~~~~~~~~~~
The core of the metadata management of KIT Data Manager is the metadata model, which is presented in the <<MetadataModel,figure below>>. The model consists of three parts:

Administrative Metadata::
   This category contains metadata elements that are mostly used internally by KIT Data Manager and its services. These elements have a fixed schema and are typically stored 
   in a relational database. One important part is the Base Metadata defining a guaranteed core set of metadata elements that are expected to be available for each and every 
   Digital Object managed by KIT Data Manager. Parts of the Base Metadata are adopted from the link:http://epubs.stfc.ac.uk/bitstream/485/csmdm.version-2.pdf[Core Scientific 
   Metadata Model (CSMD) 2.0], other parts of this model were skipped to reduce complexity and to allow more flexibility. An important part of the Base Metadata is the Object 
   Identifier (OID) which identifies each Digital Object and can be used to link additional metadata entities to a Base Metadata entity. All administrative metadata elements 
   may or may not be exposed to the user by according service interfaces.
Data Organization Metadata::
   The Data Organization Metadata contains information on how data managed by KIT Data Manager is organized and where it is located. Currently, only file-based 
   Data Organization is supported and all Data Organization information is stored in relational databases. For more information please refer to chapter 
   <<ChapterDataOrganization,Data Organization>>.
Content Metadata::
   The third part of the metadata model is the content metadata. Content metadata covers for example community-specific metadata providing detailed information about the 
   content of a Digital Object. For the sake of flexibility all content metadata related implementations are outsourced into a separate module called Enhanced Metadata Module 
   (see <<ChapterEnhancedMetadataArchitecture,Extension: Enhanced Metadata Module>>) that can be installed optionally to the basic KIT Data Manager distribution.
  
[[MetadataModel]]
.Metadata model of KIT Data Manager.
image::MetaData.png[Metadata model]

Administrative and Data Organization Metadata of KIT Data Manager are stored in relational databases using well defined schemas and can be accessed using Java or REST service APIs.
For content metadata there is no fixed API or schema available as content metadata strongly differs depending on the community and supported use cases. Rather there is a basic workflow
available that can be implemented in order to extract and register content metadata. How access to this metadata is realized depends on the system(s) in which the metadata
are registered. 

[[ChapterStaging]]
Staging
~~~~~~~
The term `Staging` basically stands for the process of transferring data in or out KIT Data Manager, either to access data manually or automatically for computing purposes.
As KIT Data Manager aims to be able to build up repository systems for large-scale scientific experiment data, the data transfer needs a special focus. 
In contrast to traditional repository systems KIT Data Manager has to provide reasonable throughput in order to be able to cope with the huge amounts of data 
delivered by the scientists. In addition, scientific data can be very diverse, e.g. hundred of thousands of small files vs. a handful of files in the order of terabyte.
Therefore, the process of Staging in case of an ingest (for downloads this process is carried out the other way around) is divided into two parts: 

Caching::
   Caching is the plain data transfer to a temporary storage system which is accessible in an optimal way depending on the requirement, e.g. throughput, security or 
   geographical location. To achieve best results transfers to the cache are carried out using native clients or custom, optimized transfer tools. The location where the 
   cached data can be stored is provided and set up by KIT Data Manager using pre-configured StagingAccessPoints which define the protocol as well as the remotely and locally accessible 
   location. Details about StagingAccessPoints can be found in the `Programming KIT Data Manager` or `Administration UI` chapters.
Archiving::
   During archiving the data from the cache is validated, metadata might be extracted or transfer post-processing may take place. Afterwards, the data
   is copied from the cache to a dedicated storage area where it won't be accessible directly any longer. As soon as the data is in the archive storage, it can be expected 
   to be safe. Local copies can be removed and repository workflows will start taking care of the data.

[NOTE]
Authentification and authorization for data transfers to and from the cache is not a task covered by KIT Data Manager. This offers a huge level of flexibility and allows to customzie 
the data transfer to possible needs. However, it is still possible to use the same user database that is used to obtain KIT Data Manager UserIDs, e.g. an LDAP server. The only thing that
has to be ensured is that for data ingests the written data has to be accessible by KIT Data Manager and for downloads the data, written by KIT Data Manager, must be readable by the user 
who wants to access the data. Typically, this can be achieved by running KIT Data Manager as a privileged user or by handling access permission on a group level. 

As we've just mentioned, the transfer into the archive storage is much more than a simple copy operation. The process of initially providing data associated with a 
Digital Object is called `Ingest`. During Ingest, different steps like metadata extraction, checksumming or even processing steps might be performed. For download operations 
requested data is copied first from the archive to the cache and can then be downloaded by the user using an according Access Point. Furthermore, this workflow can be also used to copy the data to an external 
location, e.g. for data processing. In order to be able to provide supplementary data (e.g. files containing metadata), a special folder structure was defined for each staging location:

.Staging Tree Structure
-----------------------------------------------
31/12/69  23:59         <DIR>    data       <1>
31/12/69  23:59         <DIR>    generated  <2>
31/12/69  23:59         <DIR>    settings   <3>
-----------------------------------------------
<1> Contains the user data, e.g. uploaded files or files for download.
<2> Contains generated data, e.g. extracted metadata or processing results
<3> Contains KIT Data Manager-related settings, e.g. credentials for third-party transfers.

<<Staging,The graphic>> below shows the general Staging workflow. At the beginning, the `Staging Service` is accessed using a `Transfer Service Interface`, which might be 
a commandline client, a Web portal or something comparable. In case of downloading data the Staging operation is scheduled and will data be made available asynchronously 
by the Staging Service as this preparation may take a while (e.g. when restoring data from tape). In case of an ingest the cache is prepared immediately. 
As soon as the preparation of the data transfer operation is finished, the data is accessible from the cache by a data consumer or can be transferred to the cache by a data producer. 
Both, cache and archive storage must be accessible by KIT Data Manager, at least one of them must be accessible (also) in a POSIX-like way. 

[[Staging]]
.Staging workflow for ingest operations with KIT Data Manager. After selecting the data (1) a Digital Object is registered (2) and a new ingest is scheduled. As soon as the transfer is prepared, the data can be transfered (3). Finally, the ingest is marked for finalization (4). 
During finalization the cached data is copied to the archive (5), the Data Organization is obtained and content metadata might be extracted automatically. Finally, extracted content metadata is made accessible e.g. by a search index (6).
image::Staging.png[Staging]

[[ChapterDataOrganization]]
Data Organization
~~~~~~~~~~~~~~~~~
The Data Organization is closely coupled with the Staging and holds information on how the data belonging to a Digital Object is organized and where it is located. 
In the most simple case, after ingesting a file tree, the Data Organization will reflect exactly this tree. This allows to restore the file tree in case of a download in 
exactly the representation the user expects. In addition, there might be attributes linked to single Data Organization items, e.g. size or mime type in the example of the file tree. 
In more sophisticated scenarios this default Data Organization might be customized according to user needs. These customizations are called `Views`. Views can be useful, 
e.g. to group all files with the same type belonging to one Digital Objects or to transform a Digital Object's data into another format. 

[[DataOrganization]]
.The graphic shows exemplarily different Views for the Data Organization of a Digital Object. On the left hand side the default View with all contained files is shown. The second View contains only the data files, the third View contains a compressed version of the default View. Finally, the View on the right hand side contains generated files with a preview of the images contained in the default View that can be mapped by their names to each other.
image::DataOrganization.png[DataOrganization]

//////////////////////////////////////////
[[ChapterDataIntensiveComputing]]
Data Intensive Computing
~~~~~~~~~~~~~~~~~~~~~~~~

[NOTE]
Not documented, yet. 
//////////////////////////////////////////
